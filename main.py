from fastapi import FastAPI
from pydantic import BaseModel
import requests
import random

app = FastAPI(title="Smart AI API", version="2.1")

class ChatRequest(BaseModel):
    message: str

def get_ai_response(user_input):
    """–ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ AI –º–æ–¥–µ–ª–∏"""
    
    # –°–ø–∏—Å–æ–∫ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç
    models = [
        "microsoft/DialoGPT-small",  # –ú–∞–ª–µ–Ω—å–∫–∞—è –Ω–æ –±—ã—Å—Ç—Ä–∞—è
        "facebook/blenderbot-400M-distill",  # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
        "microsoft/DialoGPT-large",  # –ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å
    ]
    
    for model in models:
        try:
            API_URL = f"https://api-inference.huggingface.co/models/{model}"
            
            payload = {
                "inputs": user_input,
                "parameters": {
                    "max_length": 300,
                    "temperature": 0.7,
                    "do_sample": True
                },
                "options": {
                    "wait_for_model": False  # –ù–µ –∂–¥–µ–º –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≥—Ä—É–∑–∏—Ç—Å—è
                }
            }
            
            response = requests.post(API_URL, json=payload, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    return result[0]['generated_text']
                    
        except Exception as e:
            continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
    
    # –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º DeepSeek
    try:
        return get_deepseek_response(user_input)
    except:
        return "–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π AI –ø–æ–º–æ—â–Ω–∏–∫. –°–µ–π—á–∞—Å –æ—Å–Ω–æ–≤–Ω–∞—è AI —Å–∏—Å—Ç–µ–º–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –Ω–æ —è –º–æ–≥—É –ø–æ–º–æ—á—å —Å –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º! üöÄ"

def get_deepseek_response(user_input):
    """–†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —á–µ—Ä–µ–∑ DeepSeek"""
    try:
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π API
        url = "https://free.churchless.tech/v1/chat/completions"
        
        data = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
                {"role": "user", "content": user_input}
            ],
            "temperature": 0.7
        }
        
        response = requests.post(url, json=data, timeout=20)
        
        if response.status_code == 200:
            result = response.json()
            return result["choices"][0]["message"]["content"]
    except:
        pass
    
    return None

@app.post("/smart-chat")
async def smart_chat(request: ChatRequest):
    """–£–º–Ω—ã–π —á–∞—Ç —Å –Ω–∞—Å—Ç–æ—è—â–∏–º AI"""
    user_input = request.message
    
    print(f"üí¨ –ó–∞–ø—Ä–æ—Å: {user_input}")
    
    ai_response = get_ai_response(user_input)
    
    return {
        "user_message": user_input,
        "ai_response": ai_response,
        "source": "AI Assistant",
        "type": "smart_chat"
    }

@app.post("/chat")
async def simple_chat(request: ChatRequest):
    """–ü—Ä–æ—Å—Ç–æ–π —á–∞—Ç –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    return await smart_chat(request)

@app.get("/")
def home():
    return {
        "message": "üöÄ –£–º–Ω—ã–π AI API —Ä–∞–±–æ—Ç–∞–µ—Ç!",
        "version": "2.1",
        "status": "active",
        "endpoints": {
            "POST /smart-chat": "–ù–∞—Å—Ç–æ—è—â–∏–π AI (–º—É–ª—å—Ç–∏-–º–æ–¥–µ–ª—å)",
            "POST /chat": "–ü—Ä–æ—Å—Ç–æ–π —á–∞—Ç", 
            "GET /": "–≠—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞"
        }
    }

@app.get("/health")
def health_check():
    return {
        "status": "healthy", 
        "service": "Smart AI API",
        "version": "2.1",
        "ai_models": "Multi-model fallback"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
    uvicorn.run(app, host="0.0.0.0", port=8000)
